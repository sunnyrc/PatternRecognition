{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 Gradient Descent, Linear Regression and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this who take numerical method already. The first half is sort of recap.\n",
    "\n",
    "1) Where is the minimum for\n",
    "\n",
    "$$f(x, y) = (x-2)^2 + (y-3)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = 2, y = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) After this class and for the rest of your life(except for exam) use library like this unless the library doesn't do exactly what you want(which is rare)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(xs):\n",
    "    x, y = xs #this is called variable unpacking. USE it to make your code look nicer\n",
    "    return (x-2)**2 + (y-3)**2\n",
    "\n",
    "f([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 63\n",
      "         Function evaluations: 123\n",
      "[ 1.99998368  2.99999327]\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as opt\n",
    "res = opt.fmin(f, [0,1])\n",
    "print res\n",
    "# ?opt.fmin #bring up documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Now let us understand the magic behind it. For $f(x,y)$ given above find the gradient at (1,2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\\nabla f(x,y) = 2(x-2)\\hat{x} + 2(y-3) \\hat{y}$$\n",
    "\n",
    "$$\\nabla f(1,2) = -2 \\hat{x} -2 \\hat{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\\nabla f(x,y) = 2(x-2)\\hat{x} + 2(y-3) \\hat{y}$$\n",
    "\n",
    "$$\\nabla f(1,2) = -2 \\hat{x} -2 \\hat{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Find the unit vector that has the same direction as the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$ \\frac{\\nabla f}{|\\nabla f|} = \\frac{-2\\hat{x} -2 \\hat{y}}{\\sqrt{2^2 + 2^2}} = -\\frac{1}{\\sqrt{2}} \\hat{x} -\\frac{1}{\\sqrt{2}} \\hat{y} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$ \\frac{\\nabla f}{|\\nabla f|} = \\frac{-2\\hat{x} -2 \\hat{y}}{\\sqrt{2^2 + 2^2}} = -\\frac{1}{\\sqrt{2}} \\hat{x} -\\frac{1}{\\sqrt{2}} \\hat{y} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Which direction should we walk?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Opposite to the gradient.\n",
    "\n",
    "$$ +\\frac{1}{\\sqrt{2}} \\hat{x} +\\frac{1}{\\sqrt{2}} \\hat{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Opposite to the gradient.\n",
    "\n",
    "$$ +\\frac{1}{\\sqrt{2}} \\hat{x} +\\frac{1}{\\sqrt{2}} \\hat{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) How far should we walk? What is wrong with large step size and what is wrong with small step size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"color:red\" id=\"hello\">Large step size - Stepping over the minimum<br/>\n",
    "Small step size - takes forever</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Where do we want large step size and where do we want small step size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Far away from minimum -> Large Stepsize\n",
    "\n",
    "Close to minimum -> Small Stepsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Given that we don't really know where the minimum is. How do we get a qunatity what has such behavior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$ \\text{Stepsize} = \\eta \\times |\\nabla f|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) What is a learning rate? What is wrong with large learning rate and what is wrong with small learning rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$ \\eta $ scales the step size. Large learning rate stepping over the minimum and small learning rate takes forever."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Write down the \"update rule\"\n",
    "\n",
    "$$\\vec{x}_{i+1} = \\vec{x}_{i} + \\ldots $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\\vec{x}_{i+1} = \\vec{x}_{i} + \\nabla f \\times \\eta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Given our update and learning rate of 0.01 rule compute the next guess ($\\vec{x}_{1}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$ \\vec{x}_{i+1} = 1 \\hat{x} + 2 \\hat{y} + 0.01 \\times \\left(\\frac{1}{\\sqrt{2}} \\hat{x} +\\frac{1}{\\sqrt{2}} \\hat{y}\\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) Compute ($\\vec{x}_2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Compute ($\\vec{x}_{100}$). Of course, don't do it by hands you have a computer for a reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.99995898  2.99995898]\n"
     ]
    }
   ],
   "source": [
    "xs = np.array([1., 2.])\n",
    "def f(xs):\n",
    "    x, y = xs\n",
    "    return (x-2)**2 + (y-3)**2\n",
    "\n",
    "def df(xs):\n",
    "    x, y = xs\n",
    "    return np.array([2*(x-2), 2*(y-3)])\n",
    "\n",
    "eta = 0.01\n",
    "\n",
    "for i in range(500):\n",
    "    xs = xs - eta*df(xs)\n",
    "    \n",
    "print xs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Previous example relies on analytical gradient which is not always available for us.\n",
    "\n",
    "How do we compute gradient numerically? (If you recall, there are at least 2 methods. Do you remember what's the difference between the two?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Find $\\vec{x}_{100}$ by using numerical gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.999459  2.999459]\n"
     ]
    }
   ],
   "source": [
    "xs = np.array([1., 2.])\n",
    "def f(xs):\n",
    "    x, y = xs\n",
    "    return (x-2)**2 + (y-3)**2\n",
    "\n",
    "def df(xs):\n",
    "    x, y = xs\n",
    "    h = 1e-3\n",
    "    dx = ( f(xs+np.array([h,0])) - f(xs) )/h\n",
    "    dy = ( f(xs+np.array([0,h])) - f(xs) )/h\n",
    "    return np.array([dx, dy])\n",
    "\n",
    "eta = 0.01\n",
    "\n",
    "for i in range(500):\n",
    "    xs = xs - eta*df(xs)\n",
    "    \n",
    "print xs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1) Given a bunch of data. What is the difference between good hypothesis and bad hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "good -> close to data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2) What parametrize each hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$ \\vec{w} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "3) What is padded feature? Write down the cost function with padded features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Padded features : $$[x_1, x_2, x_3, \\ldots ] \\to [1, x_1, x_2, x_3, \\ldots] $$\n",
    "\n",
    "Cost function\n",
    "$$ \\sum_{i=0}^{N} \\left( y^{(i)} - \\vec{w} \\cdot \\vec{x}^{(i)} \\right)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Padded features : $$[x_1, x_2, x_3, \\ldots ] \\to [1, x_1, x_2, x_3, \\ldots] $$\n",
    "\n",
    "Cost function\n",
    "$$ \\sum_{i=0}^{N} \\left( y^{(i)} - \\vec{w} \\cdot \\vec{x}^{(i)} \\right)^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "4) What the variable we are trying to adjust?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$\\vec{w}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) What does $w_0$ represent and what does $w_1$ represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "6) Fit this data. (use fmin if you want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "n = 20\n",
    "xs = np.linspace(1,3, n)\n",
    "ys = 3*xs + 2 + np.random.randn(n)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  5.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([[1.], [5] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.193620\n",
      "         Iterations: 72\n",
      "         Function evaluations: 137\n",
      "[ 2.05776679  2.98676089]\n"
     ]
    }
   ],
   "source": [
    "def cost(ws):\n",
    "    N = ys.size\n",
    "    s = 0.\n",
    "    for i in range(N):\n",
    "        padx = [1., xs[i]]\n",
    "        guess = np.dot(ws, padx)\n",
    "        s += (ys[i] - guess)**2\n",
    "    return s\n",
    "\n",
    "import scipy.optimize as opt\n",
    "res = opt.fmin(cost, [0.,1.])\n",
    "print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.193620\n",
      "         Iterations: 72\n",
      "         Function evaluations: 137\n",
      "[ 2.05776679  2.98676089]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x106212a50>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEACAYAAABMEua6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEfGR/wexEeJkj72C4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10458d5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xs,ys, '.')\n",
    "\n",
    "def padall(xs):\n",
    "    tmp = np.zeros((xs.size,2))\n",
    "    tmp[:, 0] = 1.\n",
    "    tmp[:, 1] = xs\n",
    "    return tmp\n",
    "\n",
    "# print np.dot( padall(xs), [2,3])\n",
    "pxs = padall(xs)\n",
    "\n",
    "def cost(ws):\n",
    "    guesses = np.dot(pxs, ws)\n",
    "    return np.sum((ys - guesses)**2)\n",
    "\n",
    "import scipy.optimize as opt\n",
    "res = opt.fmin(cost, [0.,1.])\n",
    "print res\n",
    "\n",
    "guesses = np.dot(pxs, res)\n",
    "plt.plot(xs, guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "6) Why stop at one dimension. Here you are given a data set of house price(in million) given area, bed room and bath room. Find it in house price.csv.\n",
    "\n",
    "Find the price for 45m^2 house with 2 bedroom and 2 bathroom.\n",
    "\n",
    "Hint: `np.from_text` and use numpy array slicing will save you a lot of typing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.928485\n",
      "         Iterations: 283\n",
      "         Function evaluations: 478\n",
      "[ 0.3998773   0.10027504  0.30784073  0.12015975]\n",
      "5.17931137034 5.19402447196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1070c6190>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEACAYAAACatzzfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQA0AOUegBoCcI1ADQM79P4QY/NC6mXx6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106e88750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.genfromtxt('house_price.csv', delimiter=\",\" )\n",
    "prices = data[:,0]\n",
    "features = data[:,1:]\n",
    "\n",
    "padded_features = np.zeros((features.shape[0], features.shape[1]+1))\n",
    "padded_features[:,0]  = 1.\n",
    "padded_features[:,1:] = features\n",
    "\n",
    "#padded_features[:10]\n",
    "\n",
    "\n",
    "\n",
    "ws = [1.,1.,1.,1.]\n",
    "def cost(ws):\n",
    "    guesses = np.dot(padded_features, ws)\n",
    "    return np.sum((prices-guesses)**2)\n",
    "\n",
    "import scipy.optimize as opt\n",
    "res = opt.fmin(cost, [1.,1.,1.,1.])\n",
    "print res\n",
    "\n",
    "print np.dot(padded_features[1], res), prices[1]\n",
    "guesses = np.dot(padded_features, res)\n",
    "plt.plot(guesses, prices,'.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ROC curve first? May be....\n",
    "np.from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# price, areas, bed, bath\n",
      "7.379909428359704648e+00,5.702925662014209252e+01,3.000000000000000000e+00,2.000000000000000000e+00\n",
      "5.194024471956247169e+00,3.178848728811784241e+01,4.000000000000000000e+00,3.000000000000000000e+00\n",
      "5.787643937326301113e+00,4.373214690170369323e+01,3.000000000000000000e+00,2.000000000000000000e+00\n",
      "7.794936862838272695e+00,5.576078908079323782e+01,5.000000000000000000e+00,1.000000000000000000e+00\n",
      "5.563909966753783465e+00,4.136851994961158141e+01,3.000000000000000000e+00,2.000000000000000000e+00\n",
      "8.769696250424985351e+00,6.797351226600019913e+01,4.000000000000000000e+00,1.000000000000000000e+00\n",
      "4.622648830158772704e+00,3.630680675095055676e+01,1.000000000000000000e+00,3.000000000000000000e+00\n",
      "6.639150317208280860e+00,4.551891849691049430e+01,5.000000000000000000e+00,1.000000000000000000e+00\n",
      "7.426193548120058274e+00,5.359974705889257507e+01,5.000000000000000000e+00,1.000000000000000000e+00\n",
      "6.885043957619842558e+00,4.951183165251362084e+01,4.000000000000000000e+00,1.000000000000000000e+00\n",
      "5.777352304281857087e+00,3.697373544096485176e+01,4.000000000000000000e+00,3.000000000000000000e+00\n",
      "4.776572365036786394e+00,3.872730244732842664e+01,1.000000000000000000e+00,2.000000000000000000e+00\n",
      "7.806814803733084673e+00,5.586982176820234258e+01,4.000000000000000000e+00,3.000000000000000000e+00\n",
      "5.264748274788277449e+00,3.999325636569338371e+01,2.000000000000000000e+00,2.000000000000000000e+00\n",
      "6.538806727147659537e+00,4.640991944406425773e+01,4.000000000000000000e+00,3.000000000000000000e+00\n",
      "5.552216531870709737e+00,3.190903131985716712e+01,5.000000000000000000e+00,3.000000000000000000e+00\n",
      "6.328286113070707763e+00,4.294193184143858844e+01,5.000000000000000000e+00,1.000000000000000000e+00\n",
      "6.026457978003399774e+00,4.168807034840416748e+01,5.000000000000000000e+00,1.000000000000000000e+00\n",
      "6.987376999027339330e+00,4.781642011734054876e+01,5.000000000000000000e+00,1.000000000000000000e+00\n",
      "4.955050953006256975e+00,3.241099222514144174e+01,4.000000000000000000e+00,2.000000000000000000e+00\n",
      "8.042061285266031589e+00,6.018553567362697976e+01,4.000000000000000000e+00,3.000000000000000000e+00\n",
      "6.819839759855996775e+00,5.914843321764693229e+01,1.000000000000000000e+00,3.000000000000000000e+00\n",
      "6.229315757275585952e+00,5.259043754898149103e+01,1.000000000000000000e+00,1.000000000000000000e+00\n",
      "6.853126282875438235e+00,5.856485581647620364e+01,2.000000000000000000e+00,1.000000000000000000e+00\n",
      "6.913738486221395974e+00,5.329424322200750197e+01,3.000000000000000000e+00,2.000000000000000000e+00\n",
      "7.611805965943197805e+00,5.556556454396222477e+01,5.000000000000000000e+00,1.000000000000000000e+00\n",
      "7.316592002396051342e+00,6.180794914219572433e+01,1.000000000000000000e+00,3.000000000000000000e+00\n",
      "7.400064989838970320e+00,6.477962239617370699e+01,1.000000000000000000e+00,2.000000000000000000e+00\n",
      "6.055069758433276661e+00,4.399967592980645037e+01,3.000000000000000000e+00,2.000000000000000000e+00\n",
      "5.902178799156017952e+00,4.231598909231937711e+01,3.000000000000000000e+00,3.000000000000000000e+00\n",
      "6.535957785259342678e+00,5.414895739884904913e+01,1.000000000000000000e+00,3.000000000000000000e+00\n",
      "5.652372145135260872e+00,4.488592714885204771e+01,1.000000000000000000e+00,3.000000000000000000e+00\n",
      "8.064310035027755674e+00,6.455098559040598616e+01,3.000000000000000000e+00,2.000000000000000000e+00\n",
      "6.941464863717983214e+00,5.846373679626074704e+01,1.000000000000000000e+00,3.000000000000000000e+00\n",
      "5.625518434349868535e+00,4.692107280919856294e+01,1.000000000000000000e+00,2.000000000000000000e+00\n",
      "8.663787866611460942e+00,6.508635752136910924e+01,5.000000000000000000e+00,2.000000000000000000e+00\n",
      "5.002493429609260467e+00,3.076412824535402990e+01,4.000000000000000000e+00,3.000000000000000000e+00\n",
      "5.843594662693872621e+00,4.830292727394153474e+01,1.000000000000000000e+00,3.000000000000000000e+00\n",
      "5.804399338543106524e+00,3.676455167330056639e+01,5.000000000000000000e+00,2.000000000000000000e+00\n",
      "7.964532962393409576e+00,6.371498912776746693e+01,4.000000000000000000e+00,1.000000000000000000e+00\n",
      "5.588755174333138065e+00,3.497823237740660574e+01,5.000000000000000000e+00,1.000000000000000000e+00\n",
      "7.999584535505809058e+00,5.971682164246705327e+01,5.000000000000000000e+00,2.000000000000000000e+00\n",
      "8.399491396091102402e+00,6.390404222792044209e+01,5.000000000000000000e+00,1.000000000000000000e+00\n",
      "5.136928292935565743e+00,3.697541627702207023e+01,3.000000000000000000e+00,1.000000000000000000e+00\n",
      "6.003406744022920627e+00,4.085651792686512351e+01,4.000000000000000000e+00,3.000000000000000000e+00\n",
      "8.707923652618886123e+00,6.685692539184560701e+01,4.000000000000000000e+00,3.000000000000000000e+00\n",
      "6.796995568954478095e+00,5.598188705443133983e+01,1.000000000000000000e+00,3.000000000000000000e+00\n",
      "6.196997772928606096e+00,4.267379266891487077e+01,4.000000000000000000e+00,2.000000000000000000e+00\n",
      "6.668483523196563567e+00,4.660150821709873981e+01,4.000000000000000000e+00,2.000000000000000000e+00\n",
      "5.998168066191756687e+00,3.657674762365785881e+01,5.000000000000000000e+00,3.000000000000000000e+00\n",
      "5.268395866817553674e+00,3.785636117130342626e+01,3.000000000000000000e+00,1.000000000000000000e+00\n",
      "4.772317314910025310e+00,3.788760167801900991e+01,1.000000000000000000e+00,3.000000000000000000e+00\n",
      "8.579904503899934198e+00,6.410331630143672044e+01,5.000000000000000000e+00,2.000000000000000000e+00\n",
      "6.865823791831232370e+00,5.755898203136490565e+01,1.000000000000000000e+00,3.000000000000000000e+00\n",
      "4.895666890357505352e+00,3.408774434271074227e+01,3.000000000000000000e+00,1.000000000000000000e+00\n",
      "5.684898259173412072e+00,4.306905141079018051e+01,2.000000000000000000e+00,3.000000000000000000e+00\n",
      "6.217020206041359742e+00,5.322322311220912638e+01,1.000000000000000000e+00,2.000000000000000000e+00\n",
      "4.265669510943249421e+00,3.047692903628304606e+01,2.000000000000000000e+00,1.000000000000000000e+00\n",
      "4.718972470259397589e+00,3.870929305592264313e+01,1.000000000000000000e+00,1.000000000000000000e+00\n",
      "8.023697502469435250e+00,5.793933072681632268e+01,5.000000000000000000e+00,2.000000000000000000e+00\n",
      "5.104423287412298116e+00,4.098143412237699579e+01,1.000000000000000000e+00,2.000000000000000000e+00\n",
      "6.392322430723412552e+00,4.507854401836999614e+01,4.000000000000000000e+00,2.000000000000000000e+00\n",
      "5.210012285314496339e+00,3.166619917369304460e+01,4.000000000000000000e+00,2.000000000000000000e+00\n",
      "4.475682330102328521e+00,3.296848242506092674e+01,2.000000000000000000e+00,1.000000000000000000e+00\n",
      "5.862219020381867374e+00,4.013281710194327445e+01,4.000000000000000000e+00,2.000000000000000000e+00\n",
      "5.009436169071411094e+00,3.114377350118278898e+01,4.000000000000000000e+00,1.000000000000000000e+00\n",
      "5.044090209042430217e+00,3.697949816762355368e+01,2.000000000000000000e+00,3.000000000000000000e+00\n",
      "5.782147236805076140e+00,4.854726439689358131e+01,1.000000000000000000e+00,2.000000000000000000e+00\n",
      "7.755437820005977478e+00,6.216331500796533760e+01,4.000000000000000000e+00,1.000000000000000000e+00\n",
      "6.908416245773126185e+00,5.608192434222824829e+01,3.000000000000000000e+00,1.000000000000000000e+00\n",
      "8.762756681449539897e+00,6.615982209572609918e+01,5.000000000000000000e+00,2.000000000000000000e+00\n",
      "7.487961755346341342e+00,5.548283304473815747e+01,5.000000000000000000e+00,1.000000000000000000e+00\n",
      "6.008667473364233125e+00,5.140756255951465903e+01,1.000000000000000000e+00,1.000000000000000000e+00\n",
      "6.355294181869216352e+00,4.261942419539252569e+01,5.000000000000000000e+00,2.000000000000000000e+00\n",
      "4.597428747686626238e+00,3.447821708797193452e+01,1.000000000000000000e+00,3.000000000000000000e+00\n",
      "7.576740610268984710e+00,5.696411193132061612e+01,4.000000000000000000e+00,2.000000000000000000e+00\n",
      "6.368621181555135458e+00,5.001597317160693024e+01,3.000000000000000000e+00,1.000000000000000000e+00\n",
      "6.433553272114195032e+00,4.932333627412381816e+01,3.000000000000000000e+00,1.000000000000000000e+00\n",
      "6.763716152252571945e+00,5.403512173119825235e+01,2.000000000000000000e+00,2.000000000000000000e+00\n",
      "6.907128256541867906e+00,5.061130950759377356e+01,4.000000000000000000e+00,1.000000000000000000e+00\n",
      "7.506992015322851763e+00,6.550773796673090033e+01,1.000000000000000000e+00,1.000000000000000000e+00\n",
      "4.697849172518934857e+00,3.513278045934276150e+01,2.000000000000000000e+00,2.000000000000000000e+00\n",
      "6.011778217797968615e+00,3.835155855997487606e+01,5.000000000000000000e+00,1.000000000000000000e+00\n",
      "8.370793446882283106e+00,6.564966054392237993e+01,3.000000000000000000e+00,2.000000000000000000e+00\n",
      "5.372005722118829318e+00,3.023997579587263118e+01,5.000000000000000000e+00,3.000000000000000000e+00\n",
      "5.795082391290275581e+00,4.410119562239359681e+01,3.000000000000000000e+00,1.000000000000000000e+00\n",
      "4.467929052216419450e+00,3.025739052677826280e+01,3.000000000000000000e+00,1.000000000000000000e+00\n",
      "6.799810102322457972e+00,5.764305369979651772e+01,1.000000000000000000e+00,3.000000000000000000e+00\n",
      "6.420035424483884867e+00,5.136692232893984311e+01,2.000000000000000000e+00,2.000000000000000000e+00\n",
      "4.706753068112681682e+00,3.540207083898143026e+01,2.000000000000000000e+00,1.000000000000000000e+00\n",
      "6.919279628686564543e+00,5.603641226836049327e+01,2.000000000000000000e+00,2.000000000000000000e+00\n",
      "7.643718230899733790e+00,5.726546673522879871e+01,4.000000000000000000e+00,3.000000000000000000e+00\n",
      "4.835657326465654826e+00,3.752887015940117266e+01,1.000000000000000000e+00,3.000000000000000000e+00\n",
      "6.543769312484332801e+00,4.601817446164489667e+01,4.000000000000000000e+00,2.000000000000000000e+00\n",
      "6.088835194019892150e+00,5.420122401438368342e+01,1.000000000000000000e+00,1.000000000000000000e+00\n",
      "6.607628416822970863e+00,5.115780986955433463e+01,3.000000000000000000e+00,1.000000000000000000e+00\n",
      "7.513604965111390754e+00,5.793209544453047499e+01,4.000000000000000000e+00,1.000000000000000000e+00\n",
      "5.777380666921494878e+00,3.828975072615724429e+01,4.000000000000000000e+00,2.000000000000000000e+00\n",
      "6.413854058833850402e+00,4.773343532861623828e+01,3.000000000000000000e+00,2.000000000000000000e+00\n",
      "8.334475886673445189e+00,6.558347316921384618e+01,3.000000000000000000e+00,2.000000000000000000e+00\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cat house_price.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1) Why is linear regression not suitable for predicting probabilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Consider logistic function\n",
    "\n",
    "$$\\theta(s) = \\frac{1}{1+e^{-s}}$$\n",
    "\n",
    "Find $f(\\infty)$ and $f(-\\infty)$ and just plot the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Show that $$\\theta(-s) = 1 - \\theta(s)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Combine logistic function and linear regression to make function that takes in a bunch of features and give out a probability. What parameters parametrize your models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Given that you use hypothesis $$ P_\\vec{w}(1 | \\vec{x}) = \\theta(\\vec{w}\\cdot\\vec{x}) $$\n",
    "and that you only 2 classes (+1 and -1) what is\n",
    "\n",
    "$$ P_\\vec{w}(-1 | \\vec{x})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Use the fact from 3) write what you found in 5 in a simpler form\n",
    "\n",
    "$$\n",
    "P_\\vec{w}(y|\\vec{x}) = \\begin{cases}\n",
    "    \\ldots & y = 1 \\\\\n",
    "    \\ldots & y = -1\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Using the fact that $y\\in\\{-1, 1\\}$Convince yourself that what you wrote above is just\n",
    "\n",
    "$$ P_\\vec{w}\\left(y|\\vec{x} \\right) = \\theta\\left(y \\times \\left( \\vec{w} \\cdot \\vec{x} \\right) \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) How do we distinguish a good hypothesis from bad hypothesis? (good $\\vec{w}$ from bad $\\vec{w}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) What does likelihood represents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Let us do one concrete example here.  Calculate the likelihood for $\\vec{w}$ given these data point\n",
    "$$\\vec{w}_1 = (0,1,2)$$\n",
    "- $y = 1$, $x=[1, -1]$\n",
    "- $y = -1$, $x=[-2, 1]$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Is $\\vec{w}_2 = (1,1,1)$ a better hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) What happend when we take log of the likelihood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Write down our cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) What is the parameter that we are trying to adjust?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) Look at gold_target data file and build a system to decide whether we should dig the gold or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
